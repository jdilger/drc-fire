{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ee\n",
    "\n",
    "from fire_module_2 import step2\n",
    "from fire_module import step1\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fire scripts are broken down into 3 steps:\n",
    "1. Prepare and export baseline spatial and temporal mean and standard deviation\n",
    "    - This is specific to the year and land cover type\n",
    "2. Prepare and export NBR anomalies \n",
    "3. Export Annual burn map by land cover\n",
    "\n",
    "<img src=\"imgs/pipeline.png\" alt=\"example of workflow as a pipeline\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1(analysisYear, geometry, cover, covername)\n",
    "\n",
    "Class for initializing the first steps in the burn anomalies mapping process and key input into the second step for generating burn maps.\n",
    "\n",
    "Args:\n",
    "- paramtersIO (object): Parameters for cloud and shadow masking and dictionary of cover names and export paths.\n",
    "- analysisYear (int): The year to generate burn products.\n",
    "- geometry (ee.FeatureCollection): A feature collection of at least 1 geometry for the ROI. If there are multiple features in a collection the geometry is found with the .geometry() method.\n",
    "- cover (ee.Image): The land cover image that is described in paramterIO cover dictionary.\n",
    "- coverName (str): The land cover name to generate burn products for.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: use test geom if wanted to run test exports it much smaller (and thus faster)\n",
    "test_geom = ee.FeatureCollection(\n",
    "    \"projects/sig-misc-ee/assets/drc_fire/test_areas/test_area\")\n",
    "DRC_border = ee.FeatureCollection(\n",
    "    \"projects/ee-karistenneson/assets/BurnedBiomass/DRC_Training/DRC_Border\")\n",
    "ROC_border = ee.FeatureCollection(\n",
    "    \"projects/central-africa-silvacarbon/assets/roc_fire/tables/roc_geom\")\n",
    "# cover for drc\n",
    "drc_16 = ee.Image('projects/sig-ee/FIRE/DRC/DIAF_2000forest')\n",
    "# covers for roc\n",
    "roc_10 = ee.Image(\"projects/sig-misc-ee/assets/roc_fire/landcover/roc_forest_cover_map_2010_gaf_fin01\")\n",
    "\n",
    "# drc cover name options:\n",
    "# Forests without dry forest\n",
    "# Dry forest or open forest\n",
    "# roc cover name options:\n",
    "# Forest\n",
    "cover = roc_10\n",
    "covername = \"Forest\"\n",
    "year = 2010\n",
    "region = ROC_border\n",
    "fire = step1(year, region, cover, covername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preparing baseline step will take the longest to export. Test runs for DRC for 2016 typically finish ~12-19h.\n",
    "\n",
    "prepare_script1() returns an imagecollection of the baseline mean, and stddevs \n",
    "\n",
    "export_image_collection takes the collection to export, and a function for how to export a specific collection in this case since we are making the baseline we pass in the export_baseline_landcover function.\n",
    "\n",
    "optionally: you can set test = True to export a single image, and change the export scale exportScale=Int\n",
    "export_image_collection(image_collection, export function, test: bool = False, exportScale: int = 30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_baseline = fire.prepare_script1()\n",
    "\n",
    "fire.export_image_collection(\n",
    "    prep_baseline, fire.export_baseline_landcover)#test=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the anomalies are created for each analysis period for our analysis year. Test runs for DRC for 2016 typically finish in ~9-15h.\n",
    "\n",
    "If you neeeded to restart the notebook that is ok, but make sure the fire object has be initiated for the anomalies that need to be processed.\n",
    "\n",
    "Likewise with the previous step test and exportScale can be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_col = fire.script1()\n",
    "\n",
    "fire.export_image_collection(\n",
    "    anomaly_col, fire.export_nbr_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly the burn product cna be created for the analysis year using the 2nd step.\n",
    "\n",
    "```\n",
    "step2(step1, alpha, pVal):\n",
    "Generate yearly burn product from NBR anomalies that incorporates MODIS hotspots.\n",
    "\n",
    "Args:\n",
    "    step1 (object): The initialized object used for earlier steps.\n",
    "    alpha (float): p-value threshold for identifying fires.\n",
    "    pVal (str): A string for the p-value image to use for thresholding. Can be pval_spatial or pval_temporal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "pVal = 'pval_spatial'\n",
    "fire2 = step2()\n",
    "out = fire2.main(alpha, pVal, year, cover)\n",
    "fire2.export_burn_yearly(\n",
    "    out, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "317abaa461942b5c2f22a8d9ef3039db4eb7895dd351f17bc950470b15104933"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
